{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewakobrzynska/MachineLearning/blob/main/025_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG-1wsrbrxtP"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "There are three exercises in this notebook:\n",
        "\n",
        "1. Use the cross-validation method to test the linear regression with different $\\alpha$ values, at least three.\n",
        "2. Implement a SGD method that will train the Lasso regression for 10 epochs.\n",
        "3. Extend the Fisher's classifier to work with two features. Use the class as the $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUtk5CCLrxtU"
      },
      "source": [
        "## 1. Cross-validation linear regression\n",
        "\n",
        "You need to change the variable ``alpha`` to be a list of alphas. Next do a loop and finally compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfaX1yG9rxtU",
        "outputId": "063cde0e-9303-4212-dbf6-ef157035eb73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha: 0.0\n",
            "w0 scratch: -180.92401771633644\n",
            "w1 scratch: 1.6181424688789636\n",
            "w0 sklearn: -180.92401771633473\n",
            "w1 sklearn: 1.6181424688789574\n",
            "\n",
            "Alpha: 0.1\n",
            "w0 scratch: -101.72397080681458\n",
            "w1 scratch: 1.169787574869769\n",
            "w0 sklearn: -101.72397080681503\n",
            "w1 sklearn: 1.169787574869778\n",
            "\n",
            "Alpha: 0.5\n",
            "w0 scratch: -36.97522015716443\n",
            "w1 scratch: 0.8032416872615309\n",
            "w0 sklearn: -36.975220157164365\n",
            "w1 sklearn: 0.803241687261533\n",
            "\n",
            "Alpha: 1.0\n",
            "w0 scratch: -20.590447055498615\n",
            "w1 scratch: 0.7104861640228317\n",
            "w0 sklearn: -20.590447055498615\n",
            "w1 sklearn: 0.7104861640228313\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15, 1)\n",
        "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15, 1)\n",
        "\n",
        "x = np.c_[np.ones((15, 1)), x]\n",
        "\n",
        "I = np.identity(2)\n",
        "alphas = [0.0, 0.1, 0.5, 1.0] # change here\n",
        "\n",
        "# add 1-3 line of code here\n",
        "results = []\n",
        "for alpha in alphas:\n",
        "    w = np.linalg.inv(x.T.dot(x) + alpha * I).dot(x.T).dot(y)\n",
        "    w = w.ravel()\n",
        "\n",
        "# add 1-3 lines to compare the results\n",
        "    ridge = Ridge(alpha=alpha, fit_intercept=False).fit(X=x, y=y)\n",
        "    print(f\"Alpha: {alpha}\\n\"\n",
        "          f\"w0 scratch: {w.item(0)}\\n\"\n",
        "          f\"w1 scratch: {w.item(1)}\\n\"\n",
        "          f\"w0 sklearn: {ridge.coef_.item(0)}\\n\"\n",
        "          f\"w1 sklearn: {ridge.coef_.item(1)}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPXTrvChrxtW"
      },
      "source": [
        "## 2. Implement based on the Ridge regression example, the Lasso regression.\n",
        "\n",
        "Please implement the SGD method and compare the results with the sklearn Lasso regression results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "-tbed0ZLrxtW"
      },
      "outputs": [],
      "source": [
        "def soft_threshold(x, alpha):\n",
        "    return np.sign(x) * np.maximum(np.abs(x) - alpha, 0)\n",
        "\n",
        "def sgd(x, y, alpha, epochs=10, learning_rate=0.01):\n",
        "    n_samples, n_features = x.shape\n",
        "    w = np.zeros((n_features, 1))  # Initialize weights to zeros\n",
        "    for _ in range(epochs):\n",
        "        for i in range(n_samples):\n",
        "            x_i = x[i, :].reshape(1, -1)\n",
        "            y_i = y[i]\n",
        "            error = y_i - np.dot(x_i, w)\n",
        "            # Compute the gradient of the Lasso loss function with regularization\n",
        "            grad = -2 * x_i.T.dot(error)\n",
        "            # Update weights with soft thresholding\n",
        "            w -= learning_rate * grad\n",
        "            w = soft_threshold(w, alpha * learning_rate)\n",
        "    return w.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNxiQe34rxtX",
        "outputId": "ca1a85e0-8b6e-469e-a03a-d28aa8ad0e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn intercept: 0.0 coef: [102.36666667  26.23725365]\n",
            "SGD 10 epoch intercept: 98.08558604527279 coef: 24.054409131489134\n",
            "SGD 1000 epoch intercept: 102.92109050328455 coef: 25.360905534084104\n",
            "SGD 5000 epoch intercept: 102.92109050328455 coef: 25.360905534084104\n",
            "SGD 10000 epoch intercept: 102.92109050328455 coef: 25.360905534084104\n"
          ]
        }
      ],
      "source": [
        "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1)\n",
        "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1)\n",
        "\n",
        "x_normalized = (x - x.mean(axis=0)) / x.std(axis=0)\n",
        "x_normalized = np.c_[np.ones((15, 1)), x_normalized]\n",
        "\n",
        "alpha = 0.1\n",
        "\n",
        "# Sklearn Lasso Regression\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(alpha=alpha, fit_intercept=False).fit(X=x_normalized, y=y)\n",
        "print(\"Sklearn intercept:\", lasso.intercept_, \"coef:\", lasso.coef_)\n",
        "\n",
        "# SGD for different epochs\n",
        "epochs_list = [10, 1000, 5000, 10000]\n",
        "for epochs in epochs_list:\n",
        "    w_sgd = sgd(x_normalized, y, alpha, epochs=epochs)\n",
        "    print(f\"SGD {epochs} epoch intercept:\", w_sgd[0], \"coef:\", w_sgd[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mddc8eJ1rxtX"
      },
      "source": [
        "## 3. Extend the Fisher's classifier\n",
        "\n",
        "Please extend the targets of the ``iris_data`` variable and use it as the $y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETxif2svrxtX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "iris_df = pd.DataFrame(iris_data.data,columns=iris_data.feature_names)\n",
        "iris_df.head()\n",
        "\n",
        "x = iris_df['sepal width (cm)'].values # change here\n",
        "y = iris_df['sepal length (cm)'].values # change here\n",
        "\n",
        "dataset_size = np.size(x)\n",
        "\n",
        "mean_x, mean_y = np.mean(x), np.mean(y)\n",
        "\n",
        "SS_xy = np.sum(y * x) - dataset_size * mean_y * mean_x\n",
        "SS_xx = np.sum(x * x) - dataset_size * mean_x * mean_x\n",
        "\n",
        "a = SS_xy / SS_xx\n",
        "b = mean_y - a * mean_x\n",
        "\n",
        "\n",
        "y_pred = a * x + b"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}