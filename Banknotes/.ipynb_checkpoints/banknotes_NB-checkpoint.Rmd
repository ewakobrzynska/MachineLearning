---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region editable=true slideshow={"slide_type": ""} -->
# Counterfeit detection
<!-- #endregion -->

The task in this assignment is to detect the  counterfeit banknotes. The data set is based on [banknote authentication Data Set ](https://archive.ics.uci.edu/ml/datasets/banknote+authentication#) from UCI Machine Learning repository. The first three columns denote different parameters obtained from the photographs of the banknotes and last colum provides the label. Frankly as the dataset does not have any description I don't know  which labels corresponds to real and which to counterfeited banknotes. let's assume that label one (positive) denotes the clounterfeits. The set  [banknote_authentication.csv](./data/banknote_authentication.csv) can be found in the `data`  directory.

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as st
```

```{python}
from sklearn.metrics import classification_report, ConfusionMatrixDisplay
```

```{python}
import  matplotlib.pyplot as plt
plt.rcParams['figure.figsize']=(8,8)
```

Please insert you  firstname  and name below

```{python}
from  sklearn.model_selection import train_test_split
seed = 31287
```

```{python}
data = pd.read_csv('data/banknotes_data.csv')
```

```{python}
data.head()
```

```{python tags=c("skip")}
data.describe()
```

```{python tags=c("skip")}
data.info()
```

```{python}
data_train, data_test = train_test_split(data, test_size=0.2, shuffle=True, stratify=data.loc[:,'counterfeit'], random_state=seed)
```

```{python editable=TRUE, slideshow={'slide_type': ''}}
data_train
```

```{python}
lbls_train = data_train['counterfeit']
lbls_test = data_test['counterfeit']
```

```{python}
fig, ax = plt.subplots(1,4, figsize=(22,5))
for i in range(4):
    ax[i].hist(data_train[lbls_train==0].iloc[:,i], bins=32, histtype='step', color='blue')
    ax[i].hist(data_train[lbls_train==1].iloc[:,i], bins=32, histtype='step', color='red')
    ax[i].hist(data_train[lbls_train==0].iloc[:,i], bins=32, histtype='bar', color='lightblue', alpha=0.25)
    ax[i].hist(data_train[lbls_train==1].iloc[:,i], bins=32, histtype='bar', color='orange', alpha =0.25)
```

<!-- #region editable=true slideshow={"slide_type": ""} -->
## Problem 1
<!-- #endregion -->

Using  the [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) function construct the  Gaussian  Bayes classifier using only one feature. Which feature will you choose? Calculate the confusion matrix (normalized as to show rates), ROC AUC score and plot ROC curve. Do this both for training and validation set. Plot both curves on the same plot.  

```{python}
from sklearn.naive_bayes import GaussianNB
```

<!-- #region editable=true slideshow={"slide_type": ""} -->
__Hint__ For calculating metrics and plotting ROC curves you may use functions from scikit-learn: `roc_curve`, `roc_auc_score` and `confusion matrix`. For estimating normal distribution parameters  use `norm.fit` `from scipy.stats`. Use `norm.pdf` for normal probability density function.
<!-- #endregion -->

```{python editable=TRUE, slideshow={'slide_type': ''}}
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix
```

<!-- #region editable=true slideshow={"slide_type": ""} -->
Which feature did you choose?
<!-- #endregion -->

```{python}
# Choose the feature (let's assume it's the first one for now)
feature_idx = 0
feature_train = data_train.iloc[:, feature_idx].values.reshape(-1, 1)
feature_test = data_test.iloc[:, feature_idx].values.reshape(-1, 1)

# Initialize and train the Gaussian Naive Bayes classifier
gnb = GaussianNB()
gnb.fit(feature_train, lbls_train)

```

```{python}
# Predict and evaluate on training set
train_preds = gnb.predict(feature_train)
train_probs = gnb.predict_proba(feature_train)[:, 1]

# Predict and evaluate on test set
test_preds = gnb.predict(feature_test)
test_probs = gnb.predict_proba(feature_test)[:, 1]

# Calculate and display confusion matrix and ROC AUC score for training set
train_conf_matrix = confusion_matrix(lbls_train, train_preds, normalize='true')
train_roc_auc = roc_auc_score(lbls_train, train_probs)
train_fpr, train_tpr, _ = roc_curve(lbls_train, train_probs)

# Calculate and display confusion matrix and ROC AUC score for test set
test_conf_matrix = confusion_matrix(lbls_test, test_preds, normalize='true')
test_roc_auc = roc_auc_score(lbls_test, test_probs)
test_fpr, test_tpr, _ = roc_curve(lbls_test, test_probs)

print("Training set confusion matrix:\n", train_conf_matrix)
print("Training set ROC AUC score:", train_roc_auc)
print("Test set confusion matrix:\n", test_conf_matrix)
print("Test set ROC AUC score:", test_roc_auc)

# Plot ROC curve
plt.figure(figsize=(8, 8))
plt.plot(train_fpr, train_tpr, label=f'Training set (AUC = {train_roc_auc:.2f})')
plt.plot(test_fpr, test_tpr, label=f'Test set (AUC = {test_roc_auc:.2f})')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

```

```{python editable=TRUE, slideshow={'slide_type': ''}}
data_train
```

<!-- #region editable=true slideshow={"slide_type": ""} -->
## Problem 2
<!-- #endregion -->

<!-- #region editable=true slideshow={"slide_type": ""} -->
Same as Problem 1 but now construct Gaussian Naive Bayes using two features. Additionally  compare ROC curve obtained with this and previous  classifier on the test set. What is the improvement of AUC score on the test set?
<!-- #endregion -->

```{python}
# Choose two features (assuming we use the first two for now)
features_train = data_train.iloc[:, :2].values
features_test = data_test.iloc[:, :2].values

# Initialize and train the Gaussian Naive Bayes classifier
gnb = GaussianNB()
gnb.fit(features_train, lbls_train)

```

```{python}
# Predict and evaluate on training set
train_preds = gnb.predict(features_train)
train_probs = gnb.predict_proba(features_train)[:, 1]

# Predict and evaluate on test set
test_preds = gnb.predict(features_test)
test_probs = gnb.predict_proba(features_test)[:, 1]

# Calculate and display confusion matrix and ROC AUC score for training set
train_conf_matrix = confusion_matrix(lbls_train, train_preds, normalize='true')
train_roc_auc = roc_auc_score(lbls_train, train_probs)
train_fpr, train_tpr, _ = roc_curve(lbls_train, train_probs)

# Calculate and display confusion matrix and ROC AUC score for test set
test_conf_matrix = confusion_matrix(lbls_test, test_preds, normalize='true')
test_roc_auc = roc_auc_score(lbls_test, test_probs)
test_fpr, test_tpr, _ = roc_curve(lbls_test, test_probs)

# Initialize and train the Gaussian Naive Bayes classifier using one feature
gnb_one_feature = GaussianNB()
gnb_one_feature.fit(features_train[:, :1], lbls_train)
train_probs_one_feature = gnb_one_feature.predict_proba(features_train[:, :1])[:, 1]
test_probs_one_feature = gnb_one_feature.predict_proba(features_test[:, :1])[:, 1]
train_roc_auc_one_feature = roc_auc_score(lbls_train, train_probs_one_feature)
test_roc_auc_one_feature = roc_auc_score(lbls_test, test_probs_one_feature)
train_fpr_one_feature, train_tpr_one_feature, _ = roc_curve(lbls_train, train_probs_one_feature)
test_fpr_one_feature, test_tpr_one_feature, _ = roc_curve(lbls_test, test_probs_one_feature)

# Initialize and train the Gaussian Naive Bayes classifier using two features
gnb_two_features = GaussianNB()
gnb_two_features.fit(features_train, lbls_train)
train_probs_two_features = gnb_two_features.predict_proba(features_train)[:, 1]
test_probs_two_features = gnb_two_features.predict_proba(features_test)[:, 1]
train_roc_auc_two_features = roc_auc_score(lbls_train, train_probs_two_features)
test_roc_auc_two_features = roc_auc_score(lbls_test, test_probs_two_features)
train_fpr_two_features, train_tpr_two_features, _ = roc_curve(lbls_train, train_probs_two_features)
test_fpr_two_features, test_tpr_two_features, _ = roc_curve(lbls_test, test_probs_two_features)

# Print ROC AUC scores
print("ROC AUC score with one feature - Training set:", train_roc_auc_one_feature)
print("ROC AUC score with one feature - Test set:", test_roc_auc_one_feature)
print("ROC AUC score with two features - Training set:", train_roc_auc_two_features)
print("ROC AUC score with two features - Test set:", test_roc_auc_two_features)

# Plot ROC curves
plt.figure(figsize=(8, 8))
plt.plot(train_fpr_one_feature, train_tpr_one_feature, label=f'Training set - One feature (AUC = {train_roc_auc_one_feature:.2f})')
plt.plot(test_fpr_one_feature, test_tpr_one_feature, label=f'Test set - One feature (AUC = {test_roc_auc_one_feature:.2f})')
plt.plot(train_fpr_two_features, train_tpr_two_features, label=f'Training set - Two features (AUC = {train_roc_auc_two_features:.2f})')
plt.plot(test_fpr_two_features, test_tpr_two_features, label=f'Test set - Two features (AUC = {test_roc_auc_two_features:.2f})')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

```

<!-- #region editable=true slideshow={"slide_type": ""} -->
## Problem 3
<!-- #endregion -->

```{python editable=TRUE, slideshow={'slide_type': ''}, raw_mimetype="", active="", eval=FALSE}
Same as Problem 2 but now implement Gaussian Naive Bayes using all features. Show confusion matrix only for test set. Compare all three ROC curves on the test set, same with AUC score.
```

```{python}
# Use all features
all_features_train = data_train.iloc[:, :-1].values
all_features_test = data_test.iloc[:, :-1].values

# Initialize and train the Gaussian Naive Bayes classifier
gnb = GaussianNB()
gnb.fit(all_features_train, lbls_train)

```

```{python}
# Predict and evaluate on training set
train_preds = gnb.predict(all_features_train)
train_probs = gnb.predict_proba(all_features_train)[:, 1]

# Predict and evaluate on test set
test_preds = gnb.predict(all_features_test)
test_probs = gnb.predict_proba(all_features_test)[:, 1]

# Calculate and display confusion matrix and ROC AUC score for training set
train_conf_matrix = confusion_matrix(lbls_train, train_preds, normalize='true')
train_roc_auc = roc_auc_score(lbls_train, train_probs)
train_fpr, train_tpr, _ = roc_curve(lbls_train, train_probs)

# Calculate and display confusion matrix and ROC AUC score for test set
test_conf_matrix = confusion_matrix(lbls_test, test_preds, normalize='true')
test_roc_auc = roc_auc_score(lbls_test, test_probs)
test_fpr, test_tpr, _ = roc_curve(lbls_test, test_probs)

print("Training set confusion matrix:\n", train_conf_matrix)
print("Training set ROC AUC score:", train_roc_auc)
print("Test set confusion matrix:\n", test_conf_matrix)
print("Test set ROC AUC score:", test_roc_auc)

# Plot ROC curve
plt.figure(figsize=(8, 8))
plt.plot(train_fpr, train_tpr, label=f'Training set (AUC = {train_roc_auc:.2f})')
plt.plot(test_fpr, test_tpr, label=f'Test set (AUC = {test_roc_auc:.2f})')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()
```
